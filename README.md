# Book_VisionTransformer
Tutorial of ViT(Vision Transformer)
https://gihyo.jp/book/2022/978-4-297-13058-9

第1章 TransformerからVision Transformerへの進化
1-1 自然言語処理におけるTransformerの登場
1-2 Vision and languageへの拡張
1-3 コンピュータビジョンにおけるTransformer
第2章 Vision Transformerの基礎と実装
2-1 準備
2-2 ViTの全体像
2-3 Input Layer
2-4 Self-Attention
2-5 Encoder
2-6 ViTの実装
第3章 実験と可視化によるVision Transformerの探求
3-1 実験の概要
3-2 使用するデータセット
3-3 実験条件
3-4 既存手法との比較
3-5 データ拡張における比較
3-6 位置埋め込みの可視化
3-7 ViTにおける判断根拠の可視化
3-8 ViTが捉えているモノ
第4章 コンピュータビジョンタスクへの応用
4-1 コンピュータビジョンのサブタスク
4-2 画像認識への応用
4-3 物体検出、セマンティックセグメンテーションへの応用
4-4 ビデオ認識への応用
4-5 オブジェクトトラッキングへの応用
4-6 3Dビジョンへの応用
4-7 その他のコンピュータビジョンサブタスクへの応用
4-8 Transformer応用のまとめと展望
第5章 Vision and Languageタスクへの応用
5-1 Vision and Languageのサブタスク
5-2 VQAへの応用
5-3 Image Captioningへの応用
5-4 Embodied AIへの応用
5-5 その他のVision and Languageサブタスクへの応用
5-6 Vision and Languageのまとめと展望
第6章 Vision Transformerの派生手法
6-1 ViT派生手法の分類
6-2 Swin Transformer
6-3 DeiT
6-4 CvT
6-5 SegFormer
6-6 TimeSformer
6-7 MAE
第7章 Transformerの謎を読み解く
7-1 Transformerの謎に人々は驚き困惑した
7-2 Positional embeddingの謎
7-3 Multi-head Attentionの謎
7-4 Layer Normalizationの謎
第8章 Vision Transformerの謎を読み解く
8-1 ViT vs CNN vs MLPの三国時代の到来
8-2 ViTはCNNと同じく局所特徴を学習する
8-3 ViTはより形状に反応する?
8-4 ViTは早期から大域的な領域も見ている
8-5 ViTはCNNやMLPよりもノイズや敵対的攻撃に頑健？
8-6 3つのモデルの特性と使い分けの勘どころ
8-7 ViTの新常識
