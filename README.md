# Book_VisionTransformer
Tutorial of ViT(Vision Transformer)
+ https://gihyo.jp/book/2022/978-4-297-13058-9

第1章 TransformerからVision Transformerへの進化<br>
1-1 自然言語処理におけるTransformerの登場<br>
1-2 Vision and languageへの拡張<br>
1-3 コンピュータビジョンにおけるTransformer<br>

第2章 Vision Transformerの基礎と実装<br>
2-1 準備<br>
2-2 ViTの全体像<br>
2-3 Input Layer<br>
2-4 Self-Attention<br>
2-5 Encoder<br>
2-6 ViTの実装<br>

第3章 実験と可視化によるVision Transformerの探求<br>
3-1 実験の概要<br>
3-2 使用するデータセット<br>
3-3 実験条件<br>
3-4 既存手法との比較<br>
3-5 データ拡張における比較<br>
3-6 位置埋め込みの可視化<br>
3-7 ViTにおける判断根拠の可視化<br>
3-8 ViTが捉えているモノ<br>

第4章 コンピュータビジョンタスクへの応用<br>
4-1 コンピュータビジョンのサブタスク<br>
4-2 画像認識への応用<br>
4-3 物体検出、セマンティックセグメンテーションへの応用<br>
4-4 ビデオ認識への応用<br>
4-5 オブジェクトトラッキングへの応用<br>
4-6 3Dビジョンへの応用<br>
4-7 その他のコンピュータビジョンサブタスクへの応用<br>
4-8 Transformer応用のまとめと展望<br>

第5章 Vision and Languageタスクへの応用<br>
5-1 Vision and Languageのサブタスク<br>
5-2 VQAへの応用<br>
5-3 Image Captioningへの応用<br>
5-4 Embodied AIへの応用<br>
5-5 その他のVision and Languageサブタスクへの応用<br>
5-6 Vision and Languageのまとめと展望<br>

第6章 Vision Transformerの派生手法<br>
6-1 ViT派生手法の分類<br>
6-2 Swin Transformer<br>
6-3 DeiT<br>
6-4 CvT<br>
6-5 SegFormer<br>
6-6 TimeSformer<br>
6-7 MAE<br>

第7章 Transformerの謎を読み解く<br>
7-1 Transformerの謎に人々は驚き困惑した<br>
7-2 Positional embeddingの謎<br>
7-3 Multi-head Attentionの謎<br>
7-4 Layer Normalizationの謎<br>

第8章 Vision Transformerの謎を読み解く<br>
8-1 ViT vs CNN vs MLPの三国時代の到来<br>
8-2 ViTはCNNと同じく局所特徴を学習する<br>
8-3 ViTはより形状に反応する?<br>
8-4 ViTは早期から大域的な領域も見ている<br>
8-5 ViTはCNNやMLPよりもノイズや敵対的攻撃に頑健？<br>
8-6 3つのモデルの特性と使い分けの勘どころ<br>
8-7 ViTの新常識<br>

